
# Semantic Statistics


### Abstract

> This novel framework that I call **Se**mantic **Sta**tistics (SeSta) applies principles from statistical mechanics (SM) to understand why large language models (LLMs) fall into repetitive generation patterns, such as endlessly repeating tokens (also called *stuttering*). Rather than analyzing models through a specific input, this approach treats neural activations as positions in a thermodynamic phase space with a custom energy function. By calculating fundamental thermodynamic quantities like entropy, temperature, and heat capacity across a model's activation manifold, this framework aims to uncover the intrinsic properties that lead to repetition without input dependency. Initial applications include diagnosing architectural vulnerabilities to repetition loops, identifying critical temperature thresholds where phase transitions between creative and repetitive behavior occur, and potentially guiding sampling strategies that avoid these failure modes. This approach provides concrete metrics for model evaluation and improvement that can help with efficient hyperparameter tuning.

---

### Introduction

Sometimes LLMs get stuck in a loop where they **repeat the same token** over and over again. 
$$\text{The Slovenian word for a female teacher is "učitelj\_ica\_ica\_ica\_ica\_ica\_ica...}
$$
My goal is to study why these models get stuck in these single-token loops. I've had an interesting idea about combining Statistical Mechanics (SM) with LLMs, in a framework that does not explicitly depend on a specific input, but rather uses a portion of the training dataset instead.

We can take a list of activations $q$ (a vector of length $N$) from the language model as a representative point for the system. The energy $H$ is the probability of outputting the **correct** token (as given by the dataset) minus the probability of outputting the **last** token of the input: 
$$
H(\mathbf{q}) = p_{\text{correct}}(\mathbf{q}) - p_{\text{last}}(\mathbf{q})
$$
This energy is positive if the model is more likely to be correct than to repeat repeats the last token, zero if the model correctly repeats, and negative otherwise. If we run the model on the training data, when it wants to (incorrectly) repeat itself, it would get a negative spike in energy. 

Importantly, to ensure that the energy landscape is continuous and well-behaved, it's important that, among the neurons that we target, there are also **all** the neurons from the last layer (before the output layer). With this setup we unlock a bridge between LLMs and SM. 

---

### Microcanonical Recipe

By following this recipe (standard in SM), we can evaluate the thermodynamical parameters for a model, independent of any specific input:

- Position  $\mathbf{q}$  (of fixed length $N$)
- **Hamiltonian**  $H(\mathbf{q})$
- **Phase-space volume**  $\Omega(E)=\int_{H(\mathbf{q})\le E} \, d^N q$
- **Entropy**  $S(E) = \ln \Omega(E)$
- Inverse temperature $\beta=\frac{\partial S}{\partial E}$
- **Temperature**  $T(E) = \frac{1}{\beta(T)}$
- **Heat capacity**: $C(E) = \frac{\partial E}{\partial T}$
- **Free Energy** $F(E) = E - T(E)\,S(E)$

This framework returns **thermodynamic functions of the energy**, while energy itself is nor fixed. The TD quantities themselves are not dependent on any individual input, rather on the model and training dataset. 

In principle, the set of inputs $\mathcal{D}=\{{x_1, ..., x_M}\}$ could be any subset of the input space, even the entire space itself. However, if we focus on when the model stutters, it's probably a good idea to restrain $\mathcal{D}$ to the training dataset (which, importantly, is not model-specific).

A position-energy pair can be easily generated by running the model through a given input. To evaluate $\Omega$, however, we need to approximate an integral over position space $\mathcal Q$. Entropy is just a function of the energy (**no input-dependence**!). Temperature is also easy to evaluate, as it is just a 1D partial derivative.

---

### Evaluating $\Omega(E)$


The central difficulty is evaluating the phase-space volume  
$$  
\Omega(E) = \int_{H(\mathbf q) \le E} d^N q  
$$ 
which is an extremely high-dimensional integral. Importantly, **the model does not explore the $\mathcal{Q}$ space uniformly**. Instead, activations concentrate on a highly structured, low-dimensional manifold induced by the data distribution and the network’s architecture.

If we naïvely estimate $\Omega(E)$ by counting how many sampled activations satisfy $H(\mathbf q)\le E$, we implicitly assume a uniform measure over $\mathcal Q$. This assumption is generally false and can lead to severe distortions. To correctly estimate $\Omega(E)$, we must therefore **estimate the local density of representative points**, rather than only using the raw frequency of observed states.


#### 1. Empirical Manifold Sampling

We begin by running a dataset $\mathcal D$ through the model and extracting activations at a fixed layer:  
$$
{\mathbf q_1, \mathbf q_2, \dots, \mathbf q_M}, \qquad \mathbf q_i \in \mathbb R^N.  
$$

Importantly, if we decide to use only a subset of the training dataset, the inputs should be chosen at random, to avoid high correlation between points (*time* isn't a factor in this framework). Each activation is mapped to an energy value via the Hamiltonian  
$$
H_i = H(\mathbf q_i) = p_{\text{correct}}(\mathbf{q_i}) - p_{\text{last}}(\mathbf{q_i})  
$$
that uses the probabilities of guessing the correct token and of guessing the last input token. This produces our empirical set of position-energy pairs.

#### 2. Estimating the Local Density on the Activation Manifold

To recover an estimate of the true phase-space volume, we introduce a **local density correction**. Let $\rho(\mathbf q)$ denote the local sampling density of activations around $\mathbf q$, estimated via any appropriate density-estimation algorithm of choice. 

#### 3. Density of States with Volume Weights

Finally, we can estimate $\Omega(E)$ for any energy, as:
$$
\Omega(E) = \sum_i{\frac{1(H(\mathbf{q}_i)<E)}{\rho(\mathbf{q}_i)}}
$$
We have calculated all the energies and densities once. We can now efficiently estimate this function on a 1D grid of points, and plug the result back into the *recipe* to recover the thermodynamic quantities of the model, like entropy and temperature.

---

### Potential Goals

Current understanding attributes repetition to:

- **Low entropy decoding** (greedy/beam search)
- **Training data artifacts** (repetition in corpora)
- **Attention collapse** (degenerate attention patterns)
- **Diagnose models**: Compare $S(E)$ curves across architectures - do some have deeper “repetition wells”?
- **Regularization**: Add a term to training that penalizes low $H$ states (like an energy barrier).
-  **Sampling guidance**: During inference, reject steps that push $H$ below a threshold.
-  **Phase transition analogy**: Is there a critical “temperature” (diversity level) below which repetition becomes inevitable?

This framework could **unify these**: e.g., show that attention collapse causes a low-$H$ basin, which itself implies a high probability under microcanonical measure at negative energy.

---

### Testing and Experiments

To find out whether this framework could work on LLMs, I will first test it on a simple example: a one-hidden-layer-deep FFNN on a classification task. The energy is defined as:

$$E(q)=-\log p_{correct}$$

where $q$ are all the activations of the hidden layer of the model. The dimensionality is more maneggiabile, and, if the task is perfectly learnable (unique output for each input), then the energy function is also continuous. An example could be a model that takes in a binary vector inputs $\mathbf{x}$, and returns $1$ if the sum of the value is $1$.

---

### Notes
 
- Ideally you should sample randomly from the training set.
- We start from $(\text{dataset}, \text{model}, E)$ to get $(\mathbf{x}_i, \mathbf{q}_i, \mathbf{p}_i, E(\mathbf{q}_i))$
- In this framework we probably don't need the *momenta*.
- should the position be the input tokens or the activations?
- What if the problem lies outside of the $\mathcal{Q}$ space?
- Do we estimate the energy as $\frac{1}{M} \sum_i{H(\mathbf{q}_i)}$ ? Probably not.
- The framework returns $S(E)$, $T(E)$, $C(E)$, ...
- What shapes are we expecting? What do they tell about the model?
- How about volume, which is fixed in the microcanonical ensemble, together with $E$ and $N$?
- If you want positive energy, just add 1: $H(\mathbf{q}) = p_{\text{correct}}(\mathbf{q}) + \neg \, p_{\text{last}}(\mathbf{q})$
- Explore alternatives to the formula for energy
- Manifold learning to help with DE?
- The temperature $T(E)$ is not the commonly referred-to model sampling temperature $T_{\text{sam}}$ , which is not used on this case.
- $T_\text{sam}$ is what divides the logits before performing the softmax $p = \text{softmax}(\text{logits} \, / \, T_\text{sam})$
- The temperature $T(E)$ could be used to estimate the minimum sampling temperature for a model to avoid getting stuck.
- We can change the sampling temperature without re-running the model. This lets us re-compute all the TD functions **also** as a function of $T_{\text{sam}}$ .
- The framework may be able to identify a phase transition threshold, where one can find the optimal sampling temperature $T_{\text{sam}}$ to avoid stuttering **without** re-running the LLM.
- For stability purposes, first normalize $q$ by dividing it by the standard deviation $\sigma(q)$, then calculate $\Omega^*=\frac{\Omega}{\sigma^N}$, and then $S=\log(\Omega)=\log(\Omega^* \sigma^N)=\log(\Omega^*) + N \, log(\sigma)$. 
- Test framework on GPT-2 #todo make example.
- Comparing the thermodynamic properties of layers at different depths to see where "repetition wells" emerge
- #todo Connection to training dynamics: I wonder if this framework could be extended to analyze how these TD properties evolve during training, potentially identifying early indicators of models prone to repetition.
- Potential issue: the energy function $E(q)$ is not well-behaved (similar inputs may have widely different outputs). In principle, if $N$ is high-enough, this should not pose a problem.
- Defensive Sampling
- Using the entire last layer makes the energy landscape more well-behaved.
- Would it be better to use the proba/logits of the output instead of the activations?
